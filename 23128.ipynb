{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "file-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"Lab Session Data.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-purchase-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "def evaluate_purchase_data():\n",
    "    try:\n",
    "        purchase_df = pd.read_excel(excel_file, sheet_name=\"Purchase data\")\n",
    "        purchase_mat = purchase_df.iloc[:, 1:4].values\n",
    "        purchase_vals = purchase_df.iloc[:, 4].values.reshape(-1, 1)\n",
    "        mat_dimensionality = purchase_mat.shape[1]\n",
    "        vector_count = purchase_mat.shape[0]\n",
    "        mat_rank = np.linalg.matrix_rank(purchase_mat)\n",
    "        purchase_mat_pinv = np.linalg.pinv(purchase_mat)\n",
    "        item_costs = np.dot(purchase_mat_pinv, purchase_vals).flatten()\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Dimensionality: {mat_dimensionality}\")\n",
    "        print(f\"Number of Vectors: {vector_count}\")\n",
    "        print(f\"Rank of Matrix: {mat_rank}\")\n",
    "        print(f\"Item Costs: {item_costs}\")\n",
    "        return mat_dimensionality, vector_count, mat_rank, item_costs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {excel_file_path}\")\n",
    "        return None, None, None, None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read specified sheet from Excel file.\")\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-model-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "def calculate_model_vector():\n",
    "    _, _, _, item_costs = evaluate_purchase_data()\n",
    "    if item_costs is not None:\n",
    "        print(\"Evaluation Result:\")\n",
    "        print(f\"Model Vector X (Item Costs): {item_costs}\")\n",
    "        return item_costs\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classify-customers",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "def categorize_customers():\n",
    "    try:\n",
    "        purchase_df = pd.read_excel(excel_file, sheet_name=\"Purchase data\")\n",
    "        purchase_df[\"Customer Category\"] = np.where(purchase_df.iloc[:, 4] > 200, \"RICH\", \"POOR\")\n",
    "        print(\"Evaluation Result:\")\n",
    "        print(purchase_df[[\"Customer Category\"]])\n",
    "        return purchase_df[[\"Customer Category\"]]\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read 'Purchase data' from Excel.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-irctc-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "def evaluate_irctc_stock():\n",
    "    try:\n",
    "        stock_df = pd.read_excel(excel_file, sheet_name=\"IRCTC Stock Price\")\n",
    "        stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"])\n",
    "        stock_df[\"Day\"] = stock_df[\"Date\"].dt.day_name()\n",
    "        avg_price = stats.mean(stock_df[\"Price\"])\n",
    "        var_price = stats.variance(stock_df[\"Price\"])\n",
    "        wed_avg_price = stock_df[stock_df[\"Day\"] == \"Wednesday\"][\"Price\"].mean()\n",
    "        april_avg_price = stock_df[stock_df[\"Date\"].dt.month == 4][\"Price\"].mean()\n",
    "        loss_prob = (stock_df[\"Chg%\"] < 0).mean()\n",
    "        profit_prob_wed = stock_df[(stock_df[\"Day\"] == \"Wednesday\") & (stock_df[\"Chg%\"] > 0)][\"Chg%\"].count() / stock_df[stock_df[\"Day\"] == \"Wednesday\"][\"Chg%\"].count()\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Mean Price: {avg_price}\")\n",
    "        print(f\"Variance Price: {var_price}\")\n",
    "        print(f\"Wednesday Mean Price: {wed_avg_price}\")\n",
    "        print(f\"April Mean Price: {april_avg_price}\")\n",
    "        print(f\"Probability of Loss: {loss_prob}\")\n",
    "        print(f\"Probability of Profit on Wednesday: {profit_prob_wed}\")\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.scatterplot(x=stock_df[\"Day\"], y=stock_df[\"Chg%\"])\n",
    "        plt.xlabel(\"Day of the Week\")\n",
    "        plt.ylabel(\"Change %\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(\"Change % vs. Day of the Week\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return avg_price, var_price, wed_avg_price, april_avg_price, loss_prob, profit_prob_wed\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {excel_file_path}\")\n",
    "        return None, None, None, None, None, None\n",
    "    except KeyError:\n",
    "        print(\"Error: One or more required columns ('Price', 'Chg%', 'Date') are missing from the Excel sheet.\")\n",
    "        return None, None, None, None, None, None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read 'IRCTC Stock Price' from Excel.\")\n",
    "        return None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore-thyroid-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5\n",
    "def analyze_thyroid_data():\n",
    "    try:\n",
    "        thyroid_df = pd.read_excel(excel_file, sheet_name=\"thyroid0387_UCI\")\n",
    "        thyroid_df.replace('?', np.nan, inplace=True)\n",
    "        thyroid_df = thyroid_df.infer_objects()\n",
    "        missing_vals = thyroid_df.isnull().sum()\n",
    "        categorical_columns = thyroid_df.select_dtypes(include=['object']).columns\n",
    "        for column in categorical_columns:\n",
    "            thyroid_df[column] = thyroid_df[column].astype(str)\n",
    "            thyroid_df[column] = LE().fit_transform(thyroid_df[column])\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(thyroid_df.describe())\n",
    "        print(\"Missing Values:\\n\", missing_vals)\n",
    "        return thyroid_df.describe(), missing_vals\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {excel_file_path}\")\n",
    "        return None, None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read specified sheet from Excel file.\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impute-missing-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6\n",
    "def fill_missing_data():\n",
    "    try:\n",
    "        thyroid_df = pd.read_excel(excel_file, sheet_name=\"thyroid0387_UCI\")\n",
    "        thyroid_df.replace('?', np.nan, inplace=True)\n",
    "        thyroid_df = thyroid_df.infer_objects()\n",
    "        for column in thyroid_df.columns:\n",
    "            if thyroid_df[column].dtype in ['float64', 'int64']:\n",
    "                thyroid_df[column] = thyroid_df[column].fillna(thyroid_df[column].median())\n",
    "            else:\n",
    "                thyroid_df[column] = thyroid_df[column].fillna(thyroid_df[column].mode()[0])\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(thyroid_df)\n",
    "        return thyroid_df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {excel_file_path}\")\n",
    "        return None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read specified sheet from Excel file.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7\n",
    "def standardize_data():\n",
    "    thyroid_df = fill_missing_data()\n",
    "    if thyroid_df is None:\n",
    "        return None\n",
    "    categorical_columns = thyroid_df.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        thyroid_df[column] = LE().fit_transform(thyroid_df[column])\n",
    "    numerical_columns = thyroid_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    scaler = MMS()\n",
    "    thyroid_df[numerical_columns] = scaler.fit_transform(thyroid_df[numerical_columns])\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(thyroid_df)\n",
    "    return thyroid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-jaccard-smc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8\n",
    "def compute_jaccard_smc():\n",
    "    standardized_df = standardize_data()\n",
    "    if standardized_df is None:\n",
    "        return None, None\n",
    "    vec1 = standardized_df.iloc[0, :].values\n",
    "    vec2 = standardized_df.iloc[1, :].values\n",
    "    f11 = np.sum((vec1 == 1) & (vec2 == 1))\n",
    "    f00 = np.sum((vec1 == 0) & (vec2 == 0))\n",
    "    f10 = np.sum((vec1 == 1) & (vec2 == 0))\n",
    "    f01 = np.sum((vec1 == 0) & (vec2 == 1))\n",
    "    denom = (f01 + f10 + f11)\n",
    "    jaccard_coeff = f11 / denom if denom != 0 else 0\n",
    "    smc = (f11 + f00) / (f00 + f01 + f10 + f11) if (f00 + f01 + f10 + f11) != 0 else 0\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(f\"Jaccard Coefficient: {jaccard_coeff}, SMC: {smc}\")\n",
    "    return jaccard_coeff, smc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-cosine-similarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9\n",
    "def compute_cosine_similarity():\n",
    "    standardized_df = standardize_data()\n",
    "    if standardized_df is None:\n",
    "        return None\n",
    "    vec1 = standardized_df.iloc[0, :].values.reshape(1, -1)\n",
    "    vec2 = standardized_df.iloc[1, :].values.reshape(1, -1)\n",
    "    cosine_sim = cos_sim(vec1, vec2)[0][0]\n",
    "    print(\"Evaluation Result:\", cosine_sim)\n",
    "    return cosine_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-similarity-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10\n",
    "def plot_dissimilarity_heatmap():\n",
    "    standardized_df = standardize_data()\n",
    "    if standardized_df is None:\n",
    "        return None\n",
    "    df_subset = standardized_df.iloc[:20, :]\n",
    "    dissimilarity_matrix = np.zeros((20, 20))\n",
    "    for i in range(20):\n",
    "        for j in range(20):\n",
    "            if i != j:\n",
    "                dissimilarity_matrix[i, j] = np.linalg.norm(df_subset.iloc[i] - df_subset.iloc[j])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(dissimilarity_matrix, annot=False, cmap='coolwarm')\n",
    "    plt.title(\"Heatmap of Euclidean Distances (Dissimilarity)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Evaluation Result: (Euclidean Distance Matrix - Not Printed for brevity)\")\n",
    "    return dissimilarity_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
